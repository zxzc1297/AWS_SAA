# 문제 풀이 노트 (5-8편)

[↩️ 메인으로 돌아가기](../README.md)

---

## ## 문제 5: 고성능 - S3가 "너무 바빠요(503 Error)"라고 외칠 때

> **시나리오:**
> 한 데이터 분석 회사는 대규모 EC2 인스턴스 클러스터를 사용하여 매일 배치 처리 작업을 실행합니다. 이 작업은 수백만 개의 작은 로그 파일(각각 몇 킬로바이트)을 단일 Amazon S3 버킷에서 읽어옵니다. 처리 시간을 단축하기 위해 EC2 인스턴스의 수를 늘리자, Amazon S3로부터 상당수의 `HTTP 503 Slow Down` 오류가 발생하기 시작했고, 전반적인 작업 성능이 향상되지 않았습니다.
>
> **요구사항:**
> S3 오류를 제거하고 S3로부터의 데이터 읽기 처리량을 극대화하여 전체 처리 시간을 크게 단축해야 합니다.
>
> **문제:** 최고의 읽기 성능을 달성하기 위해 솔루션스 아키텍트가 취해야 할 조치는 무엇입니까?
>
> **A.** S3 버킷에서 버전 관리 및 리전 간 복제를 활성화하여 읽기 가용성을 높입니다.
>
> **B.** 순차적인 명명 체계를 사용하는 대신 로그 파일의 S3 키 이름 접두사에 무작위성을 도입합니다.
>
> **C.** Amazon S3 VPC 게이트웨이 엔드포인트를 생성하고 EC2 인스턴스의 모든 트래픽을 엔드포인트를 통해 라우팅합니다.
>
> **D.** S3 앞에 Amazon ElastiCache 클러스터를 배치하여 작은 로그 파일을 메모리에 캐시합니다.

---

### ### 풀이 및 정리

✅ **정답: B**

* **정답 분석:** 이 문제의 핵심은 **S3의 성능이 객체 키의 접두사(Prefix) 구조에 따라 결정된다**는 점을 이해하는 것입니다. 모든 요청이 동일한 접두사로 집중되면, S3 내부의 특정 파티션에 부하가 몰려 병목이 발생하고 `503` 오류를 반환합니다. 따라서 객체 키 앞에 **해시값이나 무작위 문자열을 추가하여 접두사를 분산**시키면, 요청이 여러 파티션으로 분산되어 S3의 성능을 최대로 활용할 수 있습니다.

* **핵심 개념:** S3 성능 최적화의 핵심은 **접두사(Prefix) 분산**입니다. 대규모 동시 요청 시나리오에서 `503` 오류가 발생하면, 키 네이밍 전략을 가장 먼저 검토해야 합니다.

*(👉 비효율적인 접두사와 효율적인 접두사의 예시를 그림으로 보여주면 좋을 것 같아요.)*
`[이미지: 비효율적인 S3 접두사(sequential)와 효율적인 S3 접두사(randomized) 예시]`

---

## ## 문제 6: 탄력성 - 데이터베이스의 '완벽한' 재해 복구(DR) 시나리오

> **시나리오:**
> 한 금융 회사는 핵심 거래 애플리케이션을 `ap-northeast-2`(서울) 리전에서 운영하고 있습니다. 애플리케이션 데이터베이스는 Amazon RDS for PostgreSQL에서 실행됩니다. 규제 요건으로 인해, 서울 리전 전체에 장애가 발생하는 드문 상황에 대비하여 `ap-northeast-1`(도쿄) 리전으로 장애 조치(failover)할 수 있는 재해 복구(DR) 계획이 반드시 필요합니다. 이 계획은 복구 목표 시간(RTO) 10분 미만, 복구 목표 시점(RPO) 5초 미만을 의무화합니다.
>
> **요구사항:**
> 리전 간 데이터베이스 장애 조치를 위해 엄격한 RTO 및 RPO 요구사항을 충족해야 합니다.
>
> **문제:** 이러한 요구사항을 충족하는 가장 효과적인 DR 전략은 무엇입니까?
>
> **A.** RDS 인스턴스에 다중 AZ 배포를 구성합니다. 리전 장애 발생 시, 대기 인스턴스에서 도쿄 리전의 새 인스턴스를 시작합니다.
>
> **B.** AWS Backup을 사용하여 RDS 데이터베이스의 시간별 백업을 수행하고 이를 도쿄 리전으로 복사합니다. 재해 발생 시, 최신 백업을 새 RDS 인스턴스로 복원합니다.
>
> **C.** 도쿄 리전에 RDS for PostgreSQL 데이터베이스의 리전 간 읽기 전용 복제본을 생성합니다. 재해 발생 시, 복제본을 새 주 데이터베이스로 수동으로 승격시킵니다.
>
> **D.** 데이터베이스를 Amazon Aurora PostgreSQL 호환 버전으로 마이그레이션하고, 서울을 주 리전으로, 도쿄를 보조 리전으로 하는 **Aurora Global Database**로 구성합니다.

---

### ### 풀이 및 정리

✅ **정답: D**

* **정답 분석:** RTO 10분 미만, RPO 5초 미만이라는 **매우 엄격한 수치**가 문제의 핵심이었습니다. 이럴 때를 위해 만들어진 서비스가 바로 **`Amazon Aurora Global Database`**였습니다. 전용 복제 인프라를 통해 리전 간 복제 지연을 일반적으로 **1초 미만**으로 유지하고(RPO 충족), 장애 조치는 **1분 이내**에 완료(RTO 충족)할 수 있어, 이 시나리오의 유일한 정답이었습니다.

* **핵심 개념:** 데이터베이스 DR 전략별 RTO/RPO 비교

| 전략 유형 | **대표 서비스** | **일반적인 RPO** | **일반적인 RTO** |
| :--- | :--- | :--- | :--- |
| **백업 및 복원** | S3 스냅샷 | 수십 분 ~ 수 시간 | 수십 분 ~ 수 시간 |
| **웜 스탠바이 (Warm Standby)** | RDS 리전 간 읽기 전용 복제본 | 수 초 ~ 수 분 | 수 분 ~ 수십 분 |
| **핫 스탠바이 (Hot Standby)** | Aurora Global Database | 1초 미만 | 1분 미만 |

---

## ## 문제 7: 보안 - 암호화 키, "내 키는 내가 관리한다"

> **시나리오:**
> 한 헬스케어 스타트업이 민감한 환자 개인 건강 정보(PHI)를 처리하는 새로운 애플리케이션을 AWS에 구축하고 있습니다. HIPAA와 같은 엄격한 규정 준수 요건에 따라 모든 PHI는 전송 중 및 저장 시에 암호화되어야 합니다. 또한, 회사 보안 정책에 따르면 암호화에 사용되는 암호화 키의 생성, 교체, 비활성화 등 전체 수명 주기를 회사가 직접 제어하고 감사할 수 있어야 합니다.
>
> **요구사항:**
> 이 모든 요건을 충족하면서 Amazon S3, Amazon EBS와 같은 AWS 서비스와 기본적으로 통합되는 관리형 솔루션을 구현해야 합니다.
>
> **문제:** 다음 중 가장 적절한 보안 아키텍처는 무엇입니까?
>
> **A.** 모든 데이터 전송에 HTTPS/TLS를 사용하고, S3 버킷과 EBS 볼륨에 기본 암호화 옵션(AWS 관리형 키 사용)을 활성화한다.
>
> **B.** **AWS Key Management Service(KMS)**를 사용하여 **고객 관리형 키(Customer-Managed Key)**를 생성한다. S3 버킷은 이 키를 사용하는 서버 측 암호화(SSE-KMS)로, EBS 볼륨도 동일한 키를 사용하도록 구성하고, 모든 데이터 전송에는 HTTPS를 적용한다.
>
> **C.** 애플리케이션 서버 내에서 오픈소스 라이브러리를 사용하여 모든 데이터를 암호화한 후 S3 및 EBS에 저장한다. 암호화 키는 EC2 인스턴스에 설치된 별도의 키 관리 소프트웨어에서 관리한다.
>
> **D.** **AWS CloudHSM** 클러스터를 프로비저닝하여 암호화 키를 생성하고 저장한다. 애플리케이션이 S3나 EBS에 데이터를 저장하기 전에 CloudHSM과 직접 연동하여 암호화 작업을 수행하도록 한다.

---

### ### 풀이 및 정리

✅ **정답: B**

* **정답 분석:** 이 문제의 핵심 요구사항은 **'키의 수명주기를 회사가 직접 제어하고 감사'**하는 것이었습니다. AWS 기본 암호화는 키를 AWS가 관리하므로 이 요구사항을 충족할 수 없습니다. **`AWS KMS`**에서 **`고객 관리형 키(CMK)`**를 사용하면, 키 정책, 자동 교체 등을 직접 제어하고 CloudTrail을 통해 모든 사용 내역을 감사할 수 있어 완벽한 솔루션이 됩니다.

* **핵심 개념:** KMS 키 종류별 제어권 비교

| 키 유형 | **AWS 관리형 키 (AWS Managed Key)** | **고객 관리형 키 (Customer Managed Key, CMK)** |
| :--- | :--- | :--- |
| **키 생성 및 관리** | AWS | **고객** |
| **키 정책 제어** | 불가능 | **가능** |
| **키 교체 제어** | 자동 (변경 불가) | **가능 (자동/수동)** |
| **감사 (CloudTrail)** | 제한적 | **상세한 감사 가능** |
| **적합한 경우** | 간편한 암호화가 필요할 때 | **키에 대한 제어권과 감사가 필요할 때** |

---

## ## 문제 8: 비용 최적화 - 데이터 접근 패턴, 예측할 수 있을 때 vs. 없을 때

> **시나리오:**
> 한 소셜 미디어 회사는 수백만 개의 사용자 업로드 사진을 Amazon S3 버킷에 저장합니다. 이 사진들의 접근 패턴은 매우 예측 가능합니다. 처음 30일 동안은 자주 접근하고, 다음 60일 동안은 드물게 접근하며, 90일이 지나면 거의 접근하지 않습니다. 90일 미만의 모든 사진은 즉시 볼 수 있어야 하며, 90일이 지난 사진은 몇 시간 내에 검색할 수 있으면 됩니다.
>
> **요구사항:**
> 스토리지 비용을 최소화하기 위한 자동화된 솔루션이 필요합니다.
>
> **문제:** 이러한 사진의 수명 주기를 관리하는 가장 비용 효율적이고 자동화된 솔루션은 무엇입니까?
>
> **A.** **S3 수명 주기 정책**을 구성합니다. 객체를 30일 후 **S3 Standard-Infrequent Access(Standard-IA)**로, 총 90일 후 **S3 Glacier Deep Archive**로 전환하는 규칙을 설정합니다.
>
> **B.** 버킷에서 **S3 Intelligent-Tiering**을 활성화하여 모니터링을 기반으로 액세스 계층 간에 객체를 자동으로 이동시킵니다.
>
> **C.** 객체 메타데이터를 스캔하고 적절한 스토리지 클래스로 객체를 이동하는 일일 AWS Lambda 함수를 생성합니다.
>
> **D.** 모든 사진을 S3 Standard에 저장하고 긴 캐시 TTL을 가진 Amazon CloudFront를 사용하여 스토리지 액세스 비용을 줄입니다.

---

### ### 풀이 및 정리

✅ **정답: A**

* **정답 분석:** 이 문제의 핵심 키워드는 **'매우 예측 가능한'** 접근 패턴이었습니다. 이처럼 데이터의 접근 빈도 변화를 시간 기준으로 명확히 예측할 수 있을 때는, **`S3 수명 주기 정책`**을 사용하여 특정 시점에 더 저렴한 스토리지 클래스로 직접 이동시키는 것이 가장 확실하고 비용 효율적인 방법입니다.

* **핵심 개념:** S3 데이터 티어링(Tiering) 서비스 비교

| 구분 | **S3 수명 주기 정책 (Lifecycle Policy)** | **S3 Intelligent-Tiering** |
| :--- | :--- | :--- |
| **핵심** | **시간 기반** 규칙 (Rule-based) | **접근 패턴 기반** 모니터링 (Monitoring-based) |
| **적합한 경우** | 접근 패턴을 **예측할 수 있을 때** (예: 로그 데이터) | 접근 패턴을 **예측할 수 없거나 모를 때** (예: 사용자 콘텐츠) |
| **장점** | 비용 예측이 명확함, 모든 스토리지 클래스로 전환 가능 | 관리 노력 없음, 동적으로 최적화 |
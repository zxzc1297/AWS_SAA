# 문제 풀이 노트 (45-48편)

[↩️ 메인으로 돌아가기](../README.md)

---

## 문제 45: 민감 데이터 S3 저장을 위한 암호화 키 관리 전략

> **시나리오:**
> 한 금융 서비스 회사는 고객의 매우 민감한 금융 기록을 Amazon S3 버킷에 저장하는 새로운 애플리케이션을 개발 중입니다. 회사는 엄격한 규제 및 규정 준수 요건을 따라야 합니다.
>
> **요구사항:**
> 1.  S3 버킷에 저장되는 모든 데이터는 저장 시 암호화(Encryption at Rest)되어야 합니다.
> 2.  회사는 암호화 키의 생성, 교체(Rotation), 삭제 등 키의 수명 주기(Lifecycle)를 완벽하게 통제할 수 있어야 합니다.
> 3.  누가, 어떤 목적으로 암호화 키를 사용했는지 감사하고 증명할 수 있어야 합니다.
> 4.  암호화 및 복호화 과정은 애플리케이션에 최대한 투명해야 하며, 코드 변경을 최소화하는 것을 선호합니다.
>
> **문제:**
> 이러한 모든 요구사항을 충족하는 가장 적절한 암호화 전략은 무엇입니까?
>
> A. S3 버킷의 기본 암호화 설정으로 서버 측 암호화(SSE)와 Amazon S3 관리형 키(SSE-S3)를 사용합니다.
> B. 애플리케이션 내에서 AWS Encryption SDK를 사용하여 클라이언트 측 암호화를 수행합니다.
> C. S3 버킷의 기본 암호화를 AWS Key Management Service(SSE-KMS)를 사용한 서버 측 암호화로 설정하고, AWS KMS에서 **고객 관리형 키(Customer-Managed Key)**를 생성하여 키 정책으로 접근을 제어합니다.
> D. 고객 제공 키를 사용한 서버 측 암호화(SSE-C)를 사용합니다.

### 풀이 및 정리

✅ **정답: C**

- **솔루션 분석:** 해결책은 저장 데이터 암호화, 키 수명 주기 통제, 키 사용 감사, 애플리케이션 투명성 요구사항을 모두 만족해야 합니다. **SSE-KMS**와 **고객 관리형 키(CMK)** 조합은 KMS 키 정책을 통한 접근 제어, CloudTrail을 통한 감사 기능을 제공하며 서버 측에서 암호화를 처리하므로 모든 조건을 충족합니다. SSE-S3는 통제/감사가 불가하고, 클라이언트 측 암호화는 코드 변경이 크며, SSE-C는 운영 부담이 과도합니다.

- **핵심 개념: S3 서버 측 암호화(SSE) 옵션 비교**
| 암호화 옵션 | **SSE-S3** | **SSE-KMS** | **SSE-C** |
| :--- | :--- | :--- | :--- |
| **키 관리 주체** | **AWS (Amazon S3)** | **AWS (KMS) / 고객** | **고객 (Customer)** |
| **제어 및 감사** | 제어 불가, 감사 불가 | **고객이 키 제어, CloudTrail로 감사 가능** | 고객이 키 제어, 감사는 고객 책임 |
| **추가 비용** | 없음 | KMS 키 사용 비용 발생 | 없음 |
| **핵심 특징** | 가장 간단한 기본 암호화 | **제어/감사/권한 분리가 가능한 표준 암호화** | 고객이 자체 키를 반드시 사용해야 할 때 |


---

## 문제 46: 모놀리식 애플리케이션의 안정성을 위한 시스템 분리

> **시나리오:**
> 한 이커머스 플랫폼은 고객의 주문을 처리하는 모놀리식(Monolithic) 애플리케이션을 EC2 인스턴스에서 운영하고 있습니다. 현재는 고객이 주문을 하면 웹 서버가 애플리케이션 내의 주문 처리 모듈을 직접 동기적으로 호출하는 방식입니다. 이 구조 때문에 피크 시간대에 주문 처리 모듈에 과부하가 걸려 전체 시스템이 느려지고, 심지어는 웹 서버가 다운되어 주문 데이터가 유실되는 문제도 겪고 있습니다.
>
> **요구사항:**
> 1.  **시스템 분리(Decoupling):** 사용자의 주문 요청(프론트엔드)과 실제 주문 처리 시스템(백엔드)을 분리하여 안정성을 높여야 합니다.
> 2.  **내구성(Durability):** 백엔드 처리 시스템에 장애가 발생하더라도 주문이 절대 유실되지 않아야 합니다.
> 3.  **확장성(Scalability):** 백엔드 주문 처리 시스템은 주문량에 따라 독립적으로 확장할 수 있어야 합니다.
>
> **문제:**
> 이러한 요구사항을 모두 충족하는 가장 적절한 아키텍처 변경 방안은 무엇입니까?
>
> A. 웹 서버가 주문 세부 정보를 전용 Amazon DynamoDB 테이블에 직접 쓰도록 수정합니다.
> B. Amazon SQS 표준 대기열을 생성하고, 웹 서버는 주문 메시지를 SQS로 보내도록 수정합니다. 백엔드 처리를 위한 별도의 Auto Scaling 그룹이 SQS에서 메시지를 가져가 처리하도록 구성합니다.
> C. 웹 서버가 새로운 주문이 발생할 때마다 AWS Lambda 함수를 비동기적으로 호출하도록 수정합니다.
> D. 주문 처리 모듈을 위해 새로운 Application Load Balancer와 Auto Scaling 그룹을 생성하고, 웹 서버가 이 ALB로 HTTP 요청을 보내도록 합니다.

### 풀이 및 정리

✅ **정답: B**

- **솔루션 분석:** 강하게 결합된 시스템의 안정성, 내구성, 확장성 문제를 해결하기 위한 표준 패턴은 메시지 큐를 도입하여 시스템을 분리(Decoupling)하는 것입니다. **Amazon SQS**는 메시지를 안정적으로 저장하는 버퍼 역할을 하여 프론트엔드(웹 서버)와 백엔드(주문 처리 시스템) 간의 직접적인 의존성을 제거합니다. 이를 통해 주문 유실을 방지하고, 백엔드 시스템이 SQS 큐 깊이에 따라 독립적으로 확장할 수 있는 탄력적인 아키텍처를 구현할 수 있습니다.

- **핵심 개념: SQS를 이용한 분리형 아키텍처**
| 컴포넌트 | 역할 | AWS 서비스 예시 |
| :--- | :--- | :--- |
| **생산자 (Producer)** | 메시지를 생성하여 큐에 전송 | EC2 기반 웹 서버, Lambda 함수 |
| **대기열 (Queue)** | 메시지를 안정적으로 임시 저장 (버퍼) | **Amazon SQS** |
| **소비자 (Consumer)**| 큐에서 메시지를 가져와 비동기적으로 처리 | EC2 Auto Scaling 그룹, Lambda 함수 |


---

## 문제 47: S3 객체의 수명 주기에 따른 스토리지 비용 최적화

> **시나리오:**
> 한 의료 영상 기업은 수백만 개의 이미지를 S3 Standard에 저장하고 있습니다. 접근 패턴은 첫 90일간은 빈번하고, 이후 1년까지는 가끔(몇 분 내 검색 필요), 1년 이후에는 거의 없음(12시간 내 검색 가능)으로 명확하고 예측 가능합니다.
>
> **요구사항:**
> 1.  접근 패턴에 맞춰 스토리지 비용을 자동으로 최적화해야 합니다.
>
> **문제:**
> 이러한 요구사항을 충족하는 가장 효율적이고 자동화된 방법은 무엇입니까?
>
> A. 매월 EC2에서 스크립트를 실행하여 객체를 수동으로 이동시킵니다.
> B. S3 버킷에 **S3 수명 주기 정책(Lifecycle policy)**을 구성하여, 90일 후 **S3 Standard-IA**로, 365일 후 **S3 Glacier Deep Archive**로 전환되도록 설정합니다.
> C. S3 수명 주기 정책을 구성하여 90일 후에 **S3 Glacier Instant Retrieval**로 직접 전환합니다.
> D. 버킷의 모든 신규 객체에 대해 **S3 Intelligent-Tiering** 스토리지 클래스를 사용합니다.

### 풀이 및 정리

✅ **정답: B**

- **솔루션 분석:** 데이터의 접근 패턴이 **예측 가능하고 시간 기반**일 경우, **S3 수명 주기 정책**이 가장 효율적이고 직접적인 자동화 도구입니다. 요구사항에 따라 90일 후에는 저렴하고 검색이 빠른 **S3 Standard-IA**로, 1년 후에는 가장 저렴한 장기 보관용 스토리지인 **S3 Glacier Deep Archive**로 데이터를 자동으로 전환하여 비용을 최적화할 수 있습니다. S3 Intelligent-Tiering은 접근 패턴이 불규칙하거나 알 수 없을 때 더 적합합니다.

- **핵심 개념: 주요 S3 스토리지 클래스 비교**
| 스토리지 클래스 | **주요 사용 사례** | **검색 시간** | **상대적 보관 비용** |
| :--- | :--- | :--- | :--- |
| **S3 Standard** | 자주 액세스하는 데이터 | 밀리초 | 높음 |
| **S3 Standard-IA** | 자주 액세스하지 않지만, 필요시 빠른 검색 필요 | 밀리초 | 낮음 |
| **S3 Intelligent-Tiering**| **알 수 없거나 예측 불가능한 액세스 패턴** | 밀리초 | 자동 최적화 |
| **S3 Glacier Deep Archive**| **규정 준수를 위한 최장기/최저가 보관** | 12시간 이내 | **가장 낮음** |


---

## 문제 48: 고성능 컴퓨팅(HPC) 클러스터의 네트워크 성능 최적화

> **시나리오:**
> 한 과학 연구소는 인스턴스 간에 매우 낮은 지연 시간으로 통신해야 하는 **강력하게 결합된(Tightly-coupled)** HPC 시뮬레이션을 실행합니다. 현재 성능이 인스턴스 간 네트워크 통신 속도에 의해 제약을 받고 있습니다.
>
> **요구사항:**
> 1.  인스턴스 간에 가능한 최고의 네트워크 대역폭과 가장 낮은 지연 시간을 달성해야 합니다.
> 2.  인스턴스들이 물리적으로 서로 가까이 위치하도록 보장해야 합니다.
>
> **문제:**
> 이러한 요구사항을 가장 잘 충족하는 아키텍처는 무엇입니까?
>
> A. 여러 가용 영역에 걸쳐 분산 배치 그룹(Spread Placement Group) 내에 EC2 인스턴스를 시작합니다.
> B. **Elastic Fabric Adapter(EFA)**를 지원하는 EC2 인스턴스 유형을 선택하고, 모든 인스턴스를 단일 가용 영역 내의 **클러스터 배치 그룹(Cluster Placement Group)**에 시작합니다.
> C. EC2 인스턴스들을 Network Load Balancer(NLB) 뒤에 배치합니다.
> D. 인스턴스가 실행 중인 VPC에 AWS Direct Connect 연결을 프로비저닝합니다.

### 풀이 및 정리

✅ **정답: B**

- **솔루션 분석:** 강력하게 결합된 HPC 워크로드의 네트워크 성능을 최적화하기 위한 AWS의 표준 솔루션은 **클러스터 배치 그룹**과 **Elastic Fabric Adapter(EFA)**의 조합입니다. 클러스터 배치 그룹은 인스턴스를 동일 랙에 물리적으로 가깝게 배치하여 네트워크 지연 시간을 최소화합니다. EFA는 OS 커널을 우회하는 고성능 네트워크 인터페이스로, 기존 TCP 통신보다 훨씬 낮은 지연 시간과 높은 처리량을 제공하여 인스턴스 간 통신 성능을 극대화합니다.

- **핵심 개념: EC2 배치 그룹(Placement Groups) 비교**
| 배치 그룹 유형 | **클러스터 (Cluster)** | **분산 (Spread)** | **파티션 (Partition)** |
| :--- | :--- | :--- | :--- |
| **주요 목표** | **낮은 네트워크 지연 시간, 높은 처리량** | **고가용성, 개별 인스턴스 장애 격리** | 고가용성과 내결함성의 균형 |
| **인스턴스 배치**| 단일 AZ 내의 동일한 랙에 밀집 배치 | 서로 다른 물리적 하드웨어(랙)에 분산 배치 | 여러 파티션(랙 그룹)에 균등 분산 배치 |
| **최적 워크로드**| **HPC, 머신러닝 등 강력하게 결합된 앱** | 소수의 핵심적인 인스턴스 (예: DB, Zookeeper) | 대규모 분산/복제 워크로드 (HDFS, Kafka) |

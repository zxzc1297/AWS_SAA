# 문제 풀이 노트 (37-40편)

[↩️ 메인으로 돌아가기](../README.md)

---

## 문제 37: 온프레미스 데이터의 비용 효율적인 AWS 아카이빙

> **시나리오:**
> 한 금융 분석 회사는 매일 온프레미스 데이터 센터에서 수 테라바이트(TB)의 트랜잭션 로그 파일을 생성합니다. 이 로그 파일은 규정 준수를 위해 최소 7년간 안전하게 보관해야 합니다. 데이터는 거의 분석되지 않지만, 감사 요청이 있을 경우 24시간 이내에 데이터에 접근할 수 있어야 합니다.
>
> **요구사항:**
> 1.  데이터 전송 및 장기 보관 비용을 최소화해야 합니다.
> 2.  데이터는 내구성이 매우 높은 방식으로 저장되어야 합니다.
> 3.  분석이 필요할 때 24시간 내에 데이터를 검색할 수 있어야 합니다.
> 4.  회사는 1Gbps의 안정적인 인터넷 회선을 보유하고 있지만, 데이터 전송이 업무 시간 동안의 다른 네트워크 트래픽에 영향을 주지 않아야 합니다.
>
> **문제:**
> 이러한 요구사항을 가장 비용 효율적으로 충족하는 데이터 전송 및 스토리지 전략은 무엇입니까?
>
> A. AWS Direct Connect 연결을 설정하고 S3 Standard-IA로 전환합니다.
> B. AWS DataSync 에이전트를 설치하고 대역폭을 제한하여 S3로 전송한 후 S3 Glacier Deep Archive로 전환합니다.
> C. AWS Snowball Edge를 주기적으로 주문하여 S3로 임포트한 후 S3 Glacier Deep Archive로 전환합니다.
> D. S3 Transfer Acceleration을 활성화하고 스크립트를 사용하여 S3에 업로드한 후 S3 One Zone-IA로 전환합니다.

### 풀이 및 정리

✅ **정답: B**

- **솔루션 분석:** 해결책은 데이터 전송과 스토리지 두 가지 요구사항을 최적으로 만족시켜야 합니다. **AWS DataSync**는 대역폭 제어 및 스케줄링 기능을 제공하여 반복적인 온라인 데이터 전송에 적합합니다. 장기 보관 데이터는 검색 시간(24시간 내)과 비용 요구사항을 고려할 때 가장 저렴한 스토리지 클래스인 **S3 Glacier Deep Archive**가 최적의 솔루션입니다. S3 One Zone-IA는 내구성 요구사항을 위반하며, Snowball은 반복 작업에 비효율적입니다.

- **핵심 개념: 데이터 전송 옵션 비교**
| 서비스 | 주요 사용 사례 | 특징 | 네트워크 |
| :--- | :--- | :--- | :--- |
| **AWS DataSync** | **온프레미스 ↔ AWS 간의 지속적이고 자동화된 온라인 데이터 전송** | **대역폭 제어**, 스케줄링, 전송 중 암호화, 데이터 무결성 검증 | 인터넷 / Direct Connect |
| **AWS Snowball Family** | **네트워크가 열악한 환경에서의 대규모(페타바이트급) 데이터 오프라인 전송** | 물리적 디바이스 배송, 높은 보안, 네트워크 대역폭 사용 안 함 | 없음 (오프라인) |
| **S3 Transfer Acceleration** | **전 세계에 분산된 사용자가 S3 버킷으로 파일을 빠르게 업로드** | CloudFront 엣지 로케이션 활용, 장거리 전송 속도 개선 | 인터넷 |
[Sheets로 내보내기]

---

## 문제 38: 상태 저장 웹 애플리케이션의 고가용성 및 내결함성 확보

> **시나리오:**
> 한 회사는 단일 Amazon EC2 인스턴스에서 중요한 웹 애플리케이션을 실행하고 있으며, 사용자의 세션 데이터를 EC2의 **인스턴스 스토어(Instance Store)**에 저장합니다. 이로 인해 인스턴스 재시작 시 세션 데이터가 사라지는 문제가 발생합니다.
>
> **요구사항:**
> 1.  단일 EC2 인스턴스 또는 단일 가용 영역(AZ) 장애에도 애플리케이션은 계속 서비스를 제공해야 합니다.
> 2.  사용자 세션 데이터는 인스턴스 장애 시에도 유지되어야 합니다.
> 3.  비용 효율적인 아키텍처여야 합니다.
>
> **문제:**
> 이러한 요구사항을 모두 충족하는 가장 효과적인 아키텍처는 무엇입니까?
>
> A. ALB 뒤에 단일 인스턴스 Auto Scaling 그룹을 구성하고, Amazon EFS에 세션 데이터를 저장합니다.
> B. 여러 가용 영역에 걸쳐 최소 2개의 인스턴스로 구성된 Auto Scaling 그룹과 ALB를 사용하고, Amazon ElastiCache for Redis에 세션 데이터를 저장하도록 애플리케이션을 수정합니다.
> C. 다른 가용 영역에 보조 EC2 인스턴스를 두고, Route 53 장애 조치 라우팅 정책을 구성합니다.
> D. 애플리케이션을 컨테이너화하여 Amazon EKS 클러스터에 배포하고, Amazon EFS를 사용합니다.

### 풀이 및 정리

✅ **정답: B**

- **솔루션 분석:** 이 솔루션은 '상태 비저장(Stateless) 아키텍처' 원칙을 구현합니다. 세션 데이터를 휘발성인 인스턴스 스토어에서 분리하여 외부의 공유 가능한 **Amazon ElastiCache**에 저장함으로써 상태 지속성 문제를 해결합니다. 또한 **Application Load Balancer**와 **다중 AZ Auto Scaling 그룹**을 통해 인스턴스 및 가용 영역 수준의 장애에 대한 고가용성과 내결함성을 확보합니다.

- **핵심 개념: 상태(State) 저장을 위한 AWS 서비스 비교**
| 저장소 | 유형 | 지속성(Persistence) | 주요 사용 사례 | **세션 저장소로의 평가** |
| :--- | :--- | :--- | :--- | :--- |
| **인스턴스 스토어** | 임시 블록 스토리지 | **없음** (인스턴스 중지/종료 시 소멸) | 임시 파일, 고속 버퍼, 캐시 | **절대 불가.** 인스턴스 장애 시 모든 세션 소실. |
| **Amazon EBS** | 영구 블록 스토리지 | **높음** (인스턴스와 독립적) | 부팅 볼륨, 단일 인스턴스용 DB | **부적합.** 여러 인스턴스가 동시 공유 불가. |
| **Amazon EFS** | 공유 파일 시스템 | **높음** (인스턴스와 독립적) | 여러 웹 서버의 콘텐츠 공유, CMS | **가능은 하나 비효율적.** 파일 I/O 지연 시간이 캐시보다 높음. |
| **Amazon ElastiCache**| **인메모리 캐시** | **높음** (Redis 사용 시) | **세션 관리**, 실시간 순위표, DB 캐싱 | **최적의 선택.** 매우 빠르고 여러 인스턴스가 공유 가능. |
[Sheets로 내보내기]

---

## 문제 39: 글로벌 사용자를 위한 정적 콘텐츠 전송 성능 최적화

> **시나리오:**
> 한 미디어 회사는 전 세계 사용자를 대상으로 뉴스 웹사이트를 운영하며 정적 콘텐츠(이미지 등)를 미국 동부 리전의 S3 버킷에 저장합니다. 아시아 및 유럽 사용자들이 로딩이 매우 느리다는 피드백을 보내오고 있습니다.
>
> **요구사항:**
> 1.  글로벌 사용자의 정적 콘텐츠 로딩 속도를 개선해야 합니다.
>
> **문제:**
> 이 문제를 해결하기 위한 가장 효과적이고 표준적인 방법은 무엇입니까?
>
> A. Amazon CloudFront 배포를 생성하고, S3 버킷을 오리진으로 설정합니다.
> B. S3 교차 리전 복제를 활성화하여 유럽 및 아시아 리전의 버킷으로 복제합니다.
> C. EC2 인스턴스를 더 큰 인스턴스 유형으로 교체합니다.
> D. ALB 앞에 AWS Global Accelerator를 배포합니다.

### 풀이 및 정리

✅ **정답: A**

- **솔루션 분석:** 글로벌 사용자에게 정적 콘텐츠를 저지연으로 제공하기 위한 표준 솔루션은 CDN(Content Delivery Network) 서비스인 **Amazon CloudFront**를 사용하는 것입니다. CloudFront는 전 세계 엣지 로케이션에 콘텐츠를 캐싱하여 사용자와 가장 가까운 지점에서 데이터를 제공함으로써 응답 시간을 최소화합니다. AWS Global Accelerator는 캐싱 기능이 없으며 Non-cacheable 트래픽의 네트워크 경로 최적화에 사용되므로 이 시나리오에는 부적합합니다.

- **핵심 개념: CloudFront vs. Global Accelerator 비교**
| 구분 | **Amazon CloudFront** | **AWS Global Accelerator** |
| :--- | :--- | :--- |
| **핵심 기능** | **콘텐츠 캐싱 (CDN)** | **네트워크 경로 최적화** |
| **동작 방식**| **엣지 로케이션**에서 직접 콘텐츠 응답 (캐시 히트 시) | **AWS 글로벌 네트워크**를 통해 오리진까지의 경로를 최적화 |
| **적합한 트래픽**| 캐싱 가능한 정적/동적 콘텐츠 (이미지, 동영상, API) | 캐싱 불가능한 실시간/상태 저장 트래픽 (게임, VoIP) |
[Sheets로 내보내기]

---

## 문제 40: VPC 내에서 민감한 S3 데이터에 대한 접근 통제 강화

> **시나리오:**
> 헬스케어 스타트업이 프라이빗 서브넷의 EC2 인스턴스에서 민감한 정보를 처리하여 S3 버킷에 저장합니다. 이 S3 버킷은 공용 인터넷에서 절대 접근할 수 없어야 합니다.
>
> **요구사항:**
> 1.  S3 버킷으로의 모든 접근은 VPC 내부에서만 이루어져야 합니다.
> 2.  인터넷을 통한 S3 버킷 접근은 완벽히 차단해야 합니다.
> 3.  EC2 인스턴스는 다른 AWS 서비스에도 인터넷을 거치지 않고 접근할 수 있어야 합니다.
>
> **문제:**
> 이러한 엄격한 보안 요구사항을 모두 충족시키는 가장 안전하고 효율적인 방법은 무엇입니까?
>
> A. SQS 인터페이스 엔드포인트의 ID를 기준으로 S3 버킷 정책을 설정합니다.
> B. EC2 보안 그룹의 아웃바운드 규칙에 S3의 IP 주소 범위를 허용합니다.
> C. S3용 게이트웨이 VPC 엔드포인트를 생성하고, S3 버킷 정책에 해당 엔드포인트를 통하지 않은 모든 접근을 거부(Deny)하는 문을 추가합니다.
> D. NAT 게이트웨이를 구성하여 S3에 접근하도록 합니다.

### 풀이 및 정리

✅ **정답: C**

- **솔루션 분석:** S3 버킷에 대한 네트워크 접근을 VPC 내부로 제한하는 가장 강력한 방법은 **게이트웨이 VPC 엔드포인트**와 **S3 버킷 정책**을 함께 사용하는 것입니다. 게이트웨이 엔드포인트는 VPC와 S3 간의 트래픽이 AWS 내부 네트워크를 통하도록 보장합니다. 버킷 정책에서는 `aws:sourceVpce` 조건을 사용하여 특정 엔드포인트를 통하지 않는 모든 요청을 명시적으로 거부함으로써 외부 인터넷에서의 접근을 원천 차단합니다. 다른 AWS 서비스 접근에는 인터페이스 엔드포인트를 사용합니다.

- **핵심 개념: VPC 엔드포인트 유형 비교**
| 구분 | **게이트웨이 엔드포인트** | **인터페이스 엔드포인트** |
| :--- | :--- | :--- |
| **지원 서비스** | **S3, DynamoDB** | 대부분의 AWS 서비스 (SQS, SNS, Kinesis 등) |
| **동작 방식** | VPC 라우팅 테이블에 경로 추가 (라우터 역할) | 서브넷 내에 ENI 생성 (네트워크 카드 역할) |
| **비용**| 무료 | 시간당 요금 + 데이터 처리 요금 부과 |
[Sheets로 내보내기]
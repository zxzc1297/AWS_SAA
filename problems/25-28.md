# 문제 풀이 노트 (25-28편)

[↩️ 메인으로 돌아가기](../README.md)

---

## ## 문제 25: 탄력성 - 불안정한 IoT 데이터를 안정적으로 수집하기

> **시나리오:**
> 한 스마트팜 기업은 수천 개의 IoT 센서를 농장에 배포하여 토양 습도와 온도를 측정하고 있습니다. 센서가 설치된 지역은 네트워크 연결이 불안정하여, 센서가 몇 시간 동안 오프라인 상태였다가 다시 연결될 때 버퍼링해둔 데이터를 한꺼번에 전송하는 경우가 자주 발생합니다.
>
> 현재는 EC2 인스턴스에서 실행되는 커스텀 애플리케이션으로 데이터를 수집하고 있는데, 갑작스러운 데이터 폭증(burst)으로 인해 시스템이 과부하되거나 데이터가 유실되는 문제가 발생하고 있습니다.
>
> **요구사항:**
> 1.  불안정한 네트워크와 갑작스러운 데이터 폭증 상황에서도 모든 센서 데이터를 유실 없이 안정적으로 수집해야 합니다.
> 2.  수집된 데이터는 최종적으로 Amazon S3 버킷에 저장되어야 합니다.
> 3.  솔루션은 운영 부담을 최소화하기 위해 최대한 서버리스 및 관리형 서비스로 구성되어야 합니다.
>
> **문제:** 이러한 요구사항을 가장 탄력적이고 확장성 있게 충족하는 데이터 수집 파이프라인은 무엇입니까?
>
> **A.** IoT 센서가 **Amazon API Gateway**로 데이터를 전송하고, API Gateway는 **AWS Lambda** 함수를 트리거하여 S3에 데이터를 직접 쓰도록 구성합니다.
>
> **B.** IoT 센서가 **AWS IoT Core**의 MQTT 주제(topic)로 데이터를 발행(publish)합니다. **IoT Core 규칙(Rule)**을 설정하여, 수신된 데이터를 **Amazon Kinesis Data Firehose**로 전송하고, Firehose가 데이터를 버퍼링하여 S3 버킷으로 전달하도록 구성합니다.
>
> **C.** IoT 센서가 **Amazon SQS** 대기열에 데이터를 직접 보내도록 합니다. 별도의 EC2 인스턴스 Auto Scaling 그룹이 이 대기열을 폴링하여 데이터를 S3에 저장합니다.
>
> **D.** IoT 센서가 **Application Load Balancer**를 통해 EC2 인스턴스 클러스터로 데이터를 전송합니다. EC2의 애플리케이션이 데이터를 수집하여 S3에 저장하도록 합니다.

---

### ### 풀이 및 정리

✅ **정답: B**

* **정답 분석:** 이 문제의 핵심은 **'불안정한 네트워크'**와 **'데이터 폭증'**을 안정적으로 처리하는 것이었습니다. **`AWS IoT Core`**는 경량 MQTT 프로토콜을 사용해 불안정한 네트워크 환경의 IoT 장치들을 위한 최적의 진입점 역할을 합니다. 그 뒤에 연결된 **`Amazon Kinesis Data Firehose`**는 데이터 폭증을 처리하기 위한 완벽한 버퍼입니다. Firehose는 들어오는 데이터를 모두 받아낸 뒤, 차곡차곡 모아서(버퍼링 및 배치 처리) S3에 안정적으로 전달해 줍니다. 이 전체 파이프라인이 완전 서버리스라 운영 부담이 없다는 점도 요구사항을 충족했습니다.

* **핵심 개념:** 데이터 수집을 위한 버퍼 서비스 비교

| 구분 | **Amazon Kinesis Data Firehose** | **Amazon SQS** |
| :--- | :--- | :--- |
| **데이터 유형** | **스트리밍 데이터** (로그, IoT, 클릭스트림) | **개별 메시지/작업** (주문 처리, 이메일 발송) |
| **주요 기능** | 데이터 **버퍼링, 배치, 변환 후 전송** | 메시지 **안전하게 보관 후 1:1 전달** |
| **최적 사용 사례** | 대규모 데이터를 S3, Redshift 등으로 안정적으로 수집 | 마이크로서비스 간 비동기 통신, 작업 대기열 |
| **통합** | AWS IoT Core, Kinesis Data Streams와 네이티브 통합 | Lambda, EC2 등 컴퓨팅 서비스와 강력하게 통합 |

---

## ## 문제 26: 비용 최적화 - 숨겨진 네트워크 비용 절감하기

> **시나리오:**
> 한 대규모 웹 서비스 회사는 서울 리전(`ap-northeast-2`)의 여러 가용 영역(AZ-a, AZ-c)에 걸쳐 배포된 수백 개의 EC2 인스턴스에서 대량의 로그 데이터를 생성하고 있습니다. 별도의 EC2 인스턴스로 구성된 중앙 로그 처리 클러스터 또한 고가용성을 위해 여러 가용 영역에 걸쳐 배포되어 있습니다. 현재 로그를 생성하는 인스턴스들은 가용 영역에 상관없이 무작위로 로그 처리 인스턴스에 데이터를 전송하고 있어, AZ-a의 인스턴스가 AZ-c의 처리 인스턴스로 데이터를 보내는 등, 가용 영역 간 데이터 전송(Inter-AZ Data Transfer) 비용이 상당히 많이 발생하고 있습니다.
>
> **요구사항:**
> * 시스템 전체의 고가용성(Multi-AZ)은 반드시 유지해야 합니다.
> * 가용 영역 간 데이터 전송 비용을 크게 절감해야 합니다.
>
> **문제:** 이러한 요구사항을 가장 효과적으로 충족하는 아키텍처 변경 방안은 무엇입니까?
>
> **A.** 모든 로그 생성 및 처리 인스턴스를 하나의 단일 가용 영역(Single-AZ)으로 통합하여 가용 영역 간 데이터 전송을 원천적으로 차단합니다.
>
> **B.** **각 가용 영역 내에** 소규모 로그 처리 인스턴스 그룹을 각각 배치합니다. 각 AZ의 로그 생성 인스턴스들이 **동일한 가용 영역에 있는** 처리 인스턴스에게만 로그를 보내도록 구성합니다.
>
> **C.** **AWS Direct Connect**를 사용하여 각 가용 영역을 물리적으로 연결하여 데이터 전송 비용을 할인받습니다.
>
> **D.** **VPC 인터페이스 엔드포인트**를 생성하고, 모든 인스턴스가 이 엔드포인트를 통해 통신하도록 하여 데이터 전송 비용을 면제받습니다.

---

### ### 풀이 및 정리

✅ **정답: B**

* **정답 분석:** 이 문제를 풀면서 AWS 네트워크 비용의 중요한 원칙을 배웠습니다: **"동일한 가용 영역(AZ) 내의 데이터 전송은 무료다."** 이 원칙을 활용하는 B가 정답이었습니다. 대량의 로그 데이터를 AZ 경계를 넘기지 않고 각 AZ 내에서 로컬로 처리하게 함으로써, 비용이 발생하는 가용 영역 간 데이터 전송을 원천적으로 제거할 수 있습니다. 동시에, 시스템 전체는 여전히 여러 AZ에 걸쳐 운영되므로 고가용성 요구사항도 충족합니다.

* **핵심 개념:** AWS 데이터 전송 비용의 기본 규칙

| 데이터 전송 방향 | 비용 |
| :--- | :--- |
| 인터넷 → AWS 리전 (Inbound) | **무료** |
| **동일 AZ 내 EC2 인스턴스 간** | **무료** |
| **서로 다른 AZ 간** (동일 리전) | **유료** (양방향) |
| **서로 다른 리전 간** | **유료** (양방향) |
| AWS 리전 → 인터넷 (Outbound) | **유료** |

---

## ## 문제 27: 보안 - 조직 전체의 활동을 중앙에서 감시하기

> **시나리오:**
> 한 대기업은 AWS Organizations를 사용하여 수십 개의 AWS 계정(프로덕션, 개발, 재무 등)을 중앙에서 관리하고 있습니다. 중앙 보안팀은 규정 준수 및 보안 감사를 위해, 조직 내 **모든 계정**에서 발생하는 **모든 AWS API 호출**(예: 누가 EC2 인스턴스를 시작했는지, 누가 S3 버킷을 삭제했는지 등)을 중앙에서 수집하고 모니터링해야 합니다.
>
> **요구사항:**
> 1.  조직 전체의 AWS API 활동 로그를 단일 위치로 중앙화해야 합니다.
> 2.  수집된 로그가 변경되지 않았음을 보장해야 합니다(무결성).
> 3.  구성원 계정의 관리자가 감사 로깅 설정을 임의로 변경하거나 중지할 수 없어야 합니다.
>
> **문제:** 이러한 요구사항을 가장 효과적이고 안전하게 충족하는 방법은 무엇입니까?
>
> **A.** 각 AWS 계정에서 개별적으로 AWS CloudTrail 추적(Trail)을 생성하고, 모든 로그를 '로그 아카이브' 계정에 있는 중앙 S3 버킷으로 전송하도록 구성합니다.
>
> **B.** AWS Organizations의 **관리 계정(management account)**에서 **조직 추적(Organization Trail)**을 생성합니다. 이 추적이 조직 내 모든 계정의 이벤트를 '로그 아카이브' 계정의 중앙 S3 버킷으로 전송하도록 구성하고, 로그 파일 무결성 검증을 활성화합니다.
>
> **C.** 조직 내 모든 VPC에 대해 **VPC Flow Logs**를 활성화하고, 모든 IP 트래픽 로그를 중앙 S3 버킷으로 전송하여 분석합니다.
>
> **D.** 조직 내 모든 EC2 인스턴스에 CloudWatch 에이전트를 설치하고, 시스템 및 애플리케이션 로그를 중앙 CloudWatch Logs 그룹으로 전송하도록 구성합니다.

---

### ### 풀이 및 정리

✅ **정답: B**

* **정답 분석:** '조직 전체', '중앙 관리', '변경 불가'라는 키워드를 보고 **AWS Organizations**와 통합된 기능이 정답일 것이라 생각했습니다. **`CloudTrail 조직 추적(Organization Trail)`**은 관리 계정에서 단 한 번 설정하면, 조직 내 모든 멤버 계정에 자동으로 적용되며, 멤버 계정에서는 이 설정을 변경하거나 끌 수 없습니다. 이것이 바로 '강제적인 중앙 감사' 요구사항을 충족하는 핵심이었습니다.

* **핵심 개념:** AWS의 3대 로그 구분하기

| 로그 종류 | **AWS CloudTrail** | **VPC Flow Logs** | **CloudWatch Logs (에이전트)** |
| :--- | :--- | :--- | :--- |
| **기록 대상** | **AWS API 호출** | **VPC 내 IP 트래픽** | **EC2 인스턴스 내부 로그** |
| **답하는 질문** | "누가, 언제, 어디서, 무엇을 했는가?" | "어떤 IP와 포트가 통신했는가?" | "애플리케이션/OS에 무슨 일이 있었는가?" |
| **주요 용도** | **보안 감사, 규정 준수** | 네트워크 문제 해결, 침입 탐지 | 애플리케이션 디버깅, OS 모니터링 |

---

## ## 문제 28: 탄력성 - 레거시 윈도우 앱을 클라우드에 올리기

> **시나리오:**
> 한 기업이 사내에서 사용하던 윈도우 기반의 레거시 비즈니스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 여러 EC2 인스턴스에서 동시에 실행되며, 모든 인스턴스는 중앙 파일 서버의 공유 폴더(예: `\\FILESERVER\share`)에 SMB 프로토콜을 사용하여 데이터를 읽고 씁니다. 애플리케이션은 이 공유 파일 시스템에 강하게 의존하고 있어, S3와 같은 객체 스토리지로 아키텍처를 변경하는 것은 불가능합니다.
>
> **요구사항:**
> 1.  기존 윈도우 애플리케이션이 코드 변경 없이 사용할 수 있는 SMB 프로토콜 기반의 공유 스토리지를 제공해야 합니다.
> 2.  솔루션은 단일 가용 영역(AZ)의 장애에도 서비스를 지속할 수 있도록 고가용성을 갖추어야 합니다.
> 3.  인프라 관리 부담이 적은 AWS 완전 관리형 서비스를 사용해야 합니다.
>
> **문제:** 다음 중 이러한 요구사항을 가장 잘 충족하는 솔루션은 무엇입니까?
>
> **A.** 단일 EC2 인스턴스에 Windows Server를 설치하고 대용량 EBS 볼륨을 연결하여 파일 서버를 직접 구축합니다. EBS 스냅샷을 주기적으로 생성하여 장애 발생 시 다른 AZ에 복구합니다.
>
> **B.** **Amazon EFS** 파일 시스템을 생성하고, Windows EC2 인스턴스에 NFS 클라이언트를 설치하여 마운트합니다.
>
> **C.** **다중 AZ(Multi-AZ)** 배포 옵션을 사용하여 **Amazon FSx for Windows File Server**를 생성하고, EC2 인스턴스에서 이 파일 시스템의 DNS 이름으로 연결하도록 구성합니다.
>
> **D.** **Amazon S3** 버킷을 생성하고, EC2 인스턴스에 AWS Storage Gateway의 **파일 게이트웨이(File Gateway)**를 배포하여 S3 버킷을 SMB 공유로 노출시킵니다.

---

### ### 풀이 및 정리

✅ **정답: C**

* **정답 분석:** 문제의 핵심은 **'윈도우 기반', 'SMB 프로토콜', '공유 파일 시스템', '고가용성'**이었습니다. 이 모든 키워드를 만족시키는 서비스는 바로 **`Amazon FSx for Windows File Server`**였습니다. 이 서비스는 완전 관리형 네이티브 Windows 파일 시스템을 제공하며, **`다중 AZ(Multi-AZ)` 옵션**을 통해 AZ 장애 시 자동 장애 조치(failover)까지 지원하여 고가용성 요구사항을 완벽하게 충족했습니다.

* **핵심 개념:** AWS 파일 시스템 서비스 구분하기

| 요구사항 | **최적 서비스** |
| :--- | :--- |
| **Windows** 애플리케이션, **SMB** 프로토콜 필요 | **Amazon FSx for Windows File Server** |
| **Linux** 애플리케이션, **NFS** 프로토콜 필요 | **Amazon EFS** |
| **고성능 컴퓨팅(HPC)**, 대규모 병렬 처리 | **Amazon FSx for Lustre** |